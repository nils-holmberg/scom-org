---
execute:
  eval: true
  echo: true
  output: true
engine: knitr
format:
  html:
    toc: false
    number-sections: false
    colorlinks: true
    theme: default
title: scom-org colab
---

```{r, purl=T}
#| eval: true
#| output: true

#install.packages(c('tidyverse','lme4'))
if (T) {
# load packages
library("tidyverse")
#library("quarto")
library("lme4")
# clear workspace
rm(list=ls())
}
```

```{r, purl=T}
#| eval: true
#| output: true
# working directory
if (!grepl("/qmd", getwd(), fixed=T)) {setwd("qmd/")}; getwd();
# load functions
vals_normalize <- function(x,y) {return (data.frame(id=x, nv=(y - min(y)) / (max(y) - min(y))))}
# load fb post dataset
fn = "https://raw.githubusercontent.com/nils-holmberg/scom-org/main/csv/fb-sa-230314.csv"
fn = "../csv/fb-sa-230314.csv"
dtp = read.table(fn, sep='\t', header=T, strip.white=TRUE, stringsAsFactors=FALSE)
dtp = dtp |> as_tibble() |> mutate(month=month-30)

#
dtp |> names()
```

## 240118: boxplot measures

```{r, purl=T}
#| eval: true
#| output: true

org_type_labs=c(
"culture and recreation",
"education and research",
"health",
"social services ",
"environment",
"development and housing",
"law, advocacy an politics",
#"philantropic intermediaries and voluntarism promotion",
"international"
)
```

```{r, purl=T, fig.width=20, fig.height=10}
#| eval: true
#| output: true

tmp = dtp |> as_tibble() |> 
select(c(19,22,27,14,23,25,11,6)) |>
mutate(sa_int_rel_wc=sa_int_abs/wc) |>
mutate(e_index_rel=e_index/follow) |>
mutate(e_index_rel=e_index) |>
#mutate(date=as.POSIXct(time, origin="1970-01-01", tz="UTC")) |>
mutate(date=as.Date(date)) |>
mutate(date=format(date, "%Y-%m")) |>
group_by(date, org_type) |>
summarize(
    m1_sa_val=mean(sa_val),
    m2_sa_int_abs=mean(sa_int_abs),
    m3_wc=mean(wc),
    m4_sa_int_rel_wc=mean(sa_int_rel_wc),
    #date=first(date),
    m5_e_index=mean(e_index_rel),
    m6_follow=mean(follow)
) 

# Custom labeller function with individual variable names
custom_labeller <- function(variable, value) {
  custom_labels <- c(
  m1_sa_val="sentiment valence", 
  m2_sa_int_abs="sentiment intensity",
  m3_wc="word count", 
  m4_sa_int_rel_wc="sentiment relative",
  m5_e_index="engagement index",
  m6_follow="follower count"
  )
  return(custom_labels[value])
}

tmp |> pivot_longer(cols=3:8, names_to="measure", values_to="score") |>
  ggplot(aes(x=measure, y=score, fill=as.factor(org_type))) +
  geom_boxplot() +
  scale_fill_manual(values=as.factor(tmp$org_type), labels=org_type_labs) + 
  facet_wrap(vars(measure), scales="free", labeller=as_labeller(custom_labeller)) +
  labs(
    title="measures descriptives",
    subtitle="sentiment measures and engagement",
    caption="",
    x="measure",
    y="score",
    fill="organization type"
  ) +
  theme(
    text=element_text(size=rel(5.0)),
    plot.title = element_text(size=rel(5.0), face="bold"),
    strip.text = element_text(size=rel(5.0)),
    #axis.text.x=element_text(angle=90, hjust=1),
    axis.text.x=element_blank(),  # Omit x-axis text
    axis.ticks.x=element_blank(), # Omit x-axis ticks
    legend.title = element_text(size=rel(5.0), face="bold"),
    legend.text = element_text(size=rel(5.0)),
  )
```

## 240118: measures over time, without org_type

```{r, purl=T, fig.width=20, fig.height=10}
#| eval: true
#| output: true

tmp = dtp |> as_tibble() |> 
select(c(19,22,27,14,23,25,11,6)) |>
mutate(sa_int_rel_wc=sa_int_abs/wc) |>
mutate(e_index_rel=e_index/follow) |>
mutate(e_index_rel=e_index) |>
#mutate(date=as.POSIXct(time, origin="1970-01-01", tz="UTC")) |>
mutate(date=as.Date(date)) |>
mutate(date=format(date, "%Y-%m")) |>
#group_by(date, org_type) |>
group_by(date) |>
summarize(
    m1_sa_val=mean(sa_val),
    m2_sa_int_abs=mean(sa_int_abs),
    m3_wc=mean(wc),
    m4_sa_int_rel_wc=mean(sa_int_rel_wc),
    #date=first(date),
    m5_e_index=mean(e_index_rel),
    m6_follow=mean(follow)
) 

#tmp |> as_tibble()

# Custom labeller function with individual variable names
custom_labeller <- function(variable, value) {
  custom_labels <- c(
  m1_sa_val="sentiment valence", 
  m2_sa_int_abs="sentiment intensity",
  m3_wc="word count", 
  m4_sa_int_rel_wc="sentiment relative",
  m5_e_index="engagement index",
  m6_follow="follower count"
  )
  return(custom_labels[value])
}

tmp |> pivot_longer(cols=2:7, names_to="measure", values_to="score") |>
  ggplot(aes(x=as.Date(paste0(date,"-01")), y=score)) + #, group=org_type, color=as.factor(org_type))) +
  geom_point(size=1.5) + 
  geom_smooth(method=lm, formula = y ~ x, se=F, linewidth=1.5, color="blue") +
  #scale_x_date(date_breaks = "1 year", date_labels = "%Y") + 
  #scale_x_discrete(labels=ifelse(seq_along(tmp$date) %% 2 == 1, tmp$date, "")) +
  #scale_x_discrete(labels=ifelse((1:60 - 1) %% 4 == 0, as.character(1:60), "")) +
  #scale_x_discrete(labels=ifelse(seq_along(sort(unique(tmp$date))) %% 4 == 1, sort(unique(tmp$date)), "")) +
  #scale_color_manual(values=as.factor(tmp$org_type), labels=org_type_labs) + 
  facet_wrap(vars(measure), scales="free", labeller=as_labeller(custom_labeller)) +
  labs(
    title="measures by time",
    subtitle="sentiment measures and engagement",
    caption="sentiment is increasing over time, engagment is decreasing",
    x="date of post",
    y="score",
    #color="blue"
  ) +
  theme(
    text=element_text(size=rel(5.0)),
    plot.title=element_text(size=rel(5.0), face="bold"),
    strip.text=element_text(size=rel(5.0)),
    #axis.text.x=element_text(angle=0, hjust=1),
    #legend.position = "top",
    #legend.key.size = unit(1, "cm"),
    #legend.title = element_text(size=rel(5.0), face="bold"),
    #legend.text = element_text(size=rel(5.0)),
  )
```

## 240110: back to afinn

- översätta till årtal + månad (t.ex. 2015-01)
- valens, intensitet, wc, sent/wc, över tid 

```{r, purl=T, fig.width=20, fig.height=10}
#| eval: true
#| output: true

tmp = dtp |> as_tibble() |> 
select(c(19,22,27,14,23,25,11,6)) |>
mutate(sa_int_rel_wc=sa_int_abs/wc) |>
mutate(e_index_rel=e_index/follow) |>
mutate(e_index_rel=e_index) |>
#mutate(date=as.POSIXct(time, origin="1970-01-01", tz="UTC")) |>
mutate(date=as.Date(date)) |>
mutate(date=format(date, "%Y-%m")) |>
group_by(date, org_type) |>
summarize(
    m1_sa_val=mean(sa_val),
    m2_sa_int_abs=mean(sa_int_abs),
    m3_wc=mean(wc),
    m4_sa_int_rel_wc=mean(sa_int_rel_wc),
    #date=first(date),
    m5_e_index=mean(e_index_rel),
    m6_follow=mean(follow)
) 

# Custom labeller function with individual variable names
custom_labeller <- function(variable, value) {
  custom_labels <- c(
  m1_sa_val="sentiment valence", 
  m2_sa_int_abs="sentiment intensity",
  m3_wc="word count", 
  m4_sa_int_rel_wc="sentiment relative",
  m5_e_index="engagement index",
  m6_follow="follower count"
  )
  return(custom_labels[value])
}

tmp |> pivot_longer(cols=3:8, names_to="measure", values_to="score") |>
  #ggplot(aes(x=as.Date(paste0(date,"-01")), y=score, group=org_type, color=as.factor(org_type))) +
  ggplot(aes(x=date, y=score, group=org_type, color=as.factor(org_type))) +
  geom_point(size=1.5) + 
  geom_smooth(method=lm, formula=y~x, se=F, linewidth=1.5) +
  #scale_x_date(date_breaks = "1 year", date_labels = "%Y") + 
  #scale_x_discrete(labels=ifelse(seq_along(tmp$date) %% 2 == 1, tmp$date, "")) +
  #scale_x_discrete(labels=ifelse((1:60 - 1) %% 4 == 0, as.character(1:60), "")) +
  scale_x_discrete(labels=ifelse(seq_along(sort(unique(tmp$date))) %% 4 == 1, sort(unique(tmp$date)), "")) +
  scale_color_manual(values=as.factor(tmp$org_type), labels=org_type_labs) + 
  facet_wrap(vars(measure), scales="free", labeller=as_labeller(custom_labeller)) +
  labs(
    title="measures over time",
    subtitle="sentiment measures and engagement",
    caption="sentiment is increasing over time, engagment is decreasing",
    x="date of post",
    y="score",
    color="organization type"
  ) +
  theme(
    text=element_text(size=rel(5.0)),
    plot.title = element_text(size=rel(5.0), face="bold"),
    strip.text = element_text(size=rel(5.0)),
    axis.text.x=element_text(angle=90, hjust=1),
    #legend.position = "top",
    #legend.key.size = unit(1, "cm"),
    legend.title = element_text(size=rel(5.0), face="bold"),
    legend.text = element_text(size=rel(5.0)),
  )
```

- sentiment mått vs engagement index
- sentiment extremer + exempel poster

```{r, purl=T, fig.width=16, fig.height=10}
#| eval: true
#| output: true

tmp = dtp |> 
select(c(19,22,27,14,23,25,11,6)) |>
mutate(sa_int_rel_wc=sa_int_abs/wc) |>
mutate(e_index_rel=e_index/follow) |>
mutate(e_index_rel=e_index) |>
group_by(month) |>
summarize(
    m1_sa_val=mean(sa_val),
    m2_sa_int_abs=mean(sa_int_abs),
    m3_wc=mean(wc),
    m4_sa_int_rel_wc=mean(sa_int_rel_wc),
    #date=first(date)
    m0_e_index=mean(e_index_rel)
)

tmp |> pivot_longer(cols=2:5, names_to="measure", values_to="score") |>
  ggplot(aes(x=score, y=m0_e_index)) +
  geom_point(size=1.5) + 
  geom_smooth(method=lm, linewidth=1.5, se=F) +
  facet_wrap(~measure, scales="free", nrow = 2, ncol = 2) +
  labs(
    title="engagement by sentiment",
    subtitle="association between engagement and sentiment",
    caption="flat or negative trends",
    x="sentiment",
    y="engagement",
    #color="organization type"
  ) +
  theme(
    #legend.position = "top",  # Reposition legend to top
    #legend.key.size = unit(1, "cm"),  # Change size of legend keys
    legend.text = element_text(size = 10, face = "bold")  # Change legend text appearance
  )
```

```{r, purl=F}
if (T) {
knitr::knit_exit()
#exit()
#q()
#stop("here..")
}
```

## 240104: sentiment, top and bottom

```{r, purl=T}
#| eval: true
#| output: asis

# get sentence tokenized dataframe
fp = "../tmp/fb-sa-231228-010.tsv"
tmp = read.table(fp, sep='\t', quote="", comment.char="", header=T, strip.white=TRUE, stringsAsFactors=FALSE)

# Create a single result dataframe
result_df <- tmp |> left_join(dtp |> select(id, lang), by="id") |> filter(lang=="sv") |> 
  # Extract the 10 texts with the highest sentiment scores
  arrange(desc(sa_numeric), desc(sa_score)) %>%
  mutate(category = "top") %>%
  head(10) %>%
  
  # Bind with the 10 texts with the lowest sentiment scores
  bind_rows(tmp |> left_join(dtp |> select(id, lang), by="id") |> filter(lang=="sv") |>
  arrange(sa_numeric, desc(sa_score)) %>%
  mutate(category = "bottom") %>%
  head(10)) |>

  select(id, sentence, sa_label)

#install.packages('simplermarkdown', lib="~/lib/r-cran")
#library(simplermarkdown)
cat(simplermarkdown::md_table(result_df))
```

## 240103: paper structure

```{r, purl=T}
#| eval: true
#| output: true
fp = "../tmp/fb-sa-240103.csv"
dts = read.table(fp, sep='\t', header=T, strip.white=TRUE, stringsAsFactors=FALSE)
```

### intro

- RQ1a: how to measure sentiment (transformers)
- RQ1b: factors that explain sentiment (time, org_type, followers, wordcount)
- RQ2: effects of sentiment on engagement

### methods

- posts were split into sentences
- sentences were analyzed with transformers (neg, neu, pos + confidence)
- sentiment was aggregated per post (DV)
- predictors were extracted (RQ1)
- regression analysis with 

### results

```{r, purl=T}
#| eval: true
#| output: true

# descriptive analysis
tmp = dts |> 
select(sa_numeric_sum, sa_val, time, follow, wc, org_type) |> 
pivot_longer(cols=1:5, names_to="name", values_to="value")
#facet plot bivariate
ggplot(tmp, aes(x=org_type, y=value)) +
  geom_bar(position='dodge', stat='summary', fun='mean') +
  facet_wrap(vars(name), scales="free")

tmp = dts |> 
select(sa_numeric_sum, sa_val, time, follow, wc, lang) |> 
pivot_longer(cols=1:5, names_to="name", values_to="value")
#facet plot bivariate
ggplot(tmp, aes(x=lang, y=value)) +
  geom_bar(position='dodge', stat='summary', fun='mean') +
  facet_wrap(vars(name), scales="free")
```

```{r, purl=T}
#| eval: true
#| output: true

# inferential analysis
m1 = lmer(sa_numeric_sum ~ time + follow + wc + lang + (1|org_type), data=dts)
#m1 = lm(sa_numeric_sum ~ time + follow + wc + lang, data=dts)
#m1 = lmer(sa_val ~ time + follow + wc + lang + (1|org_type), data=dts)
#
summary(m1)
```

### discussion

- some points here

## 231229: transformer sentiment

```{r, purl=T, fig.height=4, fig.width=8}
#| eval: true
#| output: true

# Load the necessary library
#library(readr)

# List of TSV file paths
#file_paths <- c('path/to/file1.tsv', 'path/to/file2.tsv', 'path/to/file3.tsv') # replace with #actual file paths

# Define the directory containing the TSV files
directory <- "../csv" # replace with the actual directory path

# Define the pattern to match numbered TSV files with two leading zeroes
pattern <- "fb-sa-231228-0[0-9]+\\.tsv$" # This pattern matches files like 'file_001.tsv', 'file_002.tsv', etc.

# Create a list of file paths for TSV files matching the pattern
file_paths <- list.files(directory, pattern = pattern, full.names = TRUE)

# Print the list of file paths
print(file_paths)

################################################

# Function to read each TSV file into a dataframe
read_tsv_file <- function(fn) {
#  read_tsv(file_path)
  read.table(fn, sep='\t', header=T, strip.white=TRUE, stringsAsFactors=FALSE)
}

# Read each file and store the dataframes in a list
list_of_dfs <- lapply(file_paths, read_tsv_file)

# Combine all dataframes into one
combined_df <- do.call(rbind, list_of_dfs)

# Assuming you have a dataframe df with an ID column named 'id'
# and other columns you want to aggregate

# Separating duplicates and uniques
duplicates <- combined_df %>% group_by(id) %>% filter(n() > 1)
uniques <- combined_df %>% group_by(id) %>% filter(n() == 1) %>% ungroup()

# Perform your desired aggregation on the duplicates
# For example, if you want to calculate the mean of a column named 'value'
aggregated_duplicates <- duplicates %>% group_by(id) %>%
summarize(
sa_numeric_mean=mean(sa_numeric_mean),
sa_numeric_sum=sum(sa_numeric_sum),
sa_scaled_mean=mean(sa_scaled_mean),
sa_scaled_sum=mean(sa_scaled_sum),
sentence_count=max(sentence_count)
) %>%
ungroup()

# Bind the aggregated duplicates back with the uniques
combined_df <- bind_rows(aggregated_duplicates, uniques)

# View the final dataframe
dim(combined_df)

# View the combined dataframe
#paste(dim(dtp), dim(combined_df))

# Find duplicates in the specified column
#dtp[duplicated(dtp$id) | duplicated(dtp$id, fromLast = TRUE), ]
#combined_df[duplicated(combined_df$id) | duplicated(combined_df$id, fromLast = TRUE), ]

```

```{r, purl=T, fig.height=4, fig.width=8}
#| eval: true
#| output: true

#fn = "../csv/fb-sa-231228-001.tsv"
#tmp = read.table(fn, sep='\t', header=T, strip.white=TRUE, stringsAsFactors=FALSE)

# Find rows in df1 that don't have matching keys in df2
#non_matching_df1 <- anti_join(dtp, combined_df, by = "id")
# Find rows in df2 that don't have matching keys in df1
#non_matching_df2 <- anti_join(combined_df, dtp, by = "id")
# View the results
#print(non_matching_df1)
#print(non_matching_df2)

# perform inner join
dts = inner_join(combined_df, dtp, by="id") |> as_tibble()

dts |> names()
#write.table(dts, "../tmp/fb-sa-240103.csv", sep="\t", quot=T, row.names=F)

long_df <- dts |> select(27,32,19,3,5) |> 
#slice_sample(n=10000) |> 
group_by(month, org_type) |> 
summarize(afinn=mean(sa_val), trans1=mean(sa_numeric_sum), trans2=mean(sa_scaled_sum)) |> 
#rename(series1=sa_numeric_sum, series2=sa_val) |> 
#gather(key="series", value="value", -time)
pivot_longer(cols=3:5, names_to="sa", values_to="score") 

# Plotting with ggplot2
ggplot(long_df, aes(x=month, y=score, group=org_type, color=as.factor(org_type))) +
  geom_point(size=0.5) + 
  geom_smooth(method=lm, linewidth=0.5, se=F) +
  facet_wrap(vars(sa))#, scales="free")
```

```{r, purl=T}
#| eval: true
#| output: true

# lme modelling
m1 = lm(sa_val ~ time + wc, data=dts)
#
summary(m1)
```

### sentiment valence over time 

```{r, purl=T}
#| eval: true
#| output: true

tmp <- dts |> 
mutate(sa_val_rel=sa_val/(sa_frq+0.01)) |>
select(27,19,3,33) |> 
group_by(month) |> 
summarize(afinn=mean(sa_val), afinn_new=mean(sa_val_rel), trans1=mean(sa_numeric_sum)) |> 
pivot_longer(cols=2:4, names_to="sa", values_to="score") 

ggplot(tmp, aes(x=month, y=score, group=sa, color=sa)) +
  geom_point(size=0.5) + 
  geom_smooth(method=lm, linewidth=0.5, se=F)
```

```{r, purl=T}
#| eval: true
#| output: true

tmp <- dts |> 
select(27,6,30) |> 
group_by(month) |> 
summarize(sc=mean(sentence_count), wc=mean(wc)) |> 
pivot_longer(cols=2:3, names_to="measure", values_to="score") |>
ggplot(aes(x=month, y=score, group=measure, color=measure)) +
geom_point(size=0.5) + 
geom_smooth(method=lm, linewidth=0.5, se=F)
```

## 231228: summarize results

```{r, purl=T, fig.height=4, fig.width=8}
#| eval: true
#| output: true

dtp |> as_tibble() |> 
select(c(22,27,13,14,17,23,24,25)) |>
group_by(month, org_type) |>
summarize_at(vars(1:6), list(mean=mean)) |> 
pivot_longer(cols=3:8, names_to="sa", values_to="score") |>
  ggplot(aes(x=month, y=score, group=org_type, color=as.factor(org_type))) +
  geom_point(size=0.5) + 
  geom_smooth(method=lm, linewidth=0.5, se=T) +
  facet_wrap(vars(sa), scales="free")
#  geom_smooth(method="loess", size=2, se=T)
```

```{r, purl=T}
#| eval: true
#| output: true

# lme modelling
m1 = lmer(e_index ~ sa_val + (1|org_type), data=dtp)
#
summary(m1)
```

```{r, purl=T}
#| eval: true
#| output: true

# lme modelling
m2 = lmer(e_index ~ sa_val + follow + month + (1|org_type), data=dtp)
#
summary(m2)
```

```{r, purl=T}
#| eval: true
#| output: true

#dtp |> slice(1000) 
#select(org_type, org) |> 
#group_by(org_type) |> 
#full_join(data.frame(org_type=1:10), by=c("org_type"), keep=T) |>
#summarize(count_distinct=n_distinct(org))

# plot theme
t_s = 18
gt = theme(
strip.text = element_text(size = t_s),
plot.title = element_text(family = "Helvetica", face = "bold", size = (t_s)), 
legend.title = element_text(size = (t_s), colour = "black",  face = "bold.italic", family = "Helvetica"), 
legend.text = element_text(size = (t_s), face = "italic", colour="black",family = "Helvetica"), 
#legend.key.size = unit(1.5, "cm"),
axis.title = element_text(family = "Helvetica", size = (t_s), colour = "black", face = "bold"),
axis.text = element_text(family = "Helvetica", colour = "black", size = (t_s)),
#aspect.ratio=4/3
)

# wide to long format
tmp = dtp |> 
select(c(1,27,6,11,14,24)) |> 
pivot_longer(cols=3:6, names_to="measure", values_to="value")

if (F) {
# descriptives
library(plyr)
bp1 <- ddply(dtp[,c(11,27)], c("org_type"), summarise,
N=length(e_index), mean=mean(e_index), sd=sd(e_index), se=sd/sqrt(N))
bp1

#facet plot bivariate
p = ggplot(tmp, aes(x=as.factor(org_type), y=value)) +
  geom_bar(position='dodge', stat='summary', fun='mean') +
  facet_wrap(vars(measure), scales="free") +
  gt
p
}
```

## 230329: sentiment analysis

```{r, purl=F}
dtp |> select(org_type, org) |> group_by(org_type) |> summarize(count_distinct=n_distinct(org))
if (F) {
knitr::knit_exit()
#exit()
#q()
#stop("here..")
}
```

## 230523: linear mixed effects approach

```{r, purl=T}
#| eval: true
#| output: true
# ivs trend lines
tmp = dtp |> as_tibble() |> select(c(27,22,14)) |> 
group_by(org_type, month) |> summarize(sa_val_mean=mean(sa_val))
# plot by org_type
tmp |> 
  ggplot(aes(month, sa_val_mean, color=as.factor(org_type))) +
  geom_point() + 
  geom_smooth(method=lm, se=FALSE) + 
  labs(x="month", y="sa_val_mean")
```

```{r, purl=T}
#| eval: true
#| output: true
# aggregate by org_type, month
tmp = left_join(dtp, dtp |> 
# normalize
select(c(1,3,22,14)) |> group_by(org) |> group_modify(~ vals_normalize(.x$id, .x$sa_val)) |> rename(sa_val_norm=nv), by=c("id")) |> 
# aggregate
select(1,3,27,22,14,24,6,29) |> group_by(org_type, month) |> summarize(sa_val_mean=mean(sa_val), sa_val_norm_mean=mean(sa_val_norm), sa_int_mean=mean(sa_int), follow_mean=mean(follow))
# ivs, wide to long
tmp = tmp |> 
pivot_longer(cols=3:6, names_to="ivs", values_to="score")
# points with trend line
tmp |> 
  ggplot(aes(x=month, y=score, group=org_type, color=as.factor(org_type))) +
  geom_point() + 
  geom_smooth(method=lm, se=FALSE) + 
  facet_wrap(vars(ivs), scales="free") +
  labs(title="engagement trend by org_type and measure", x="month", y="score")
```

### independent variables, ivs

```{r, purl=T}
#| eval: true
#| output: true
# dv1
tmp0 = dtp |> 
select(c(1,3,22,11)) |> 
group_by(org) |> 
group_modify(~ vals_normalize(.x$id, .x$e_index)) |>
rename(e_index_norm=nv)
# iv1
tmp1 = dtp |> 
select(c(1,3,22,14)) |> 
group_by(org) |> 
group_modify(~ vals_normalize(.x$id, .x$sa_val)) |>
rename(sa_val_norm=nv)
# iv2
tmp2 = dtp |> 
select(c(1,3,22,24)) |> 
group_by(org) |> 
group_modify(~ vals_normalize(.x$id, .x$sa_int)) |>
rename(sa_int_norm=nv)
# iv3
tmp3 = dtp |> 
select(c(1,3,22,6)) |> 
group_by(org) |> 
group_modify(~ vals_normalize(.x$id, .x$follow)) |>
rename(follow_norm=nv)
# iv4
tmp4 = vals_normalize(dtp$id, dtp$time) |> as_tibble() |> rename(time_norm=nv)
# combine
tmp = tmp0 |> 
left_join(dtp |> select(id, month, org_type, out), by=c("id")) |> 
left_join(tmp1, by=c("id")) |> 
left_join(tmp2, by=c("id")) |> 
left_join(tmp3, by=c("id")) |> 
left_join(tmp4, by=c("id")) |> rename(org=org.x)
#
```

```{r, purl=T}
#| eval: true
#| output: true
# lme modelling
m1 = lmer(data=tmp, subset=out!=1, e_index_norm ~ sa_val_norm + sa_int_norm + follow_norm + time_norm + (1|org))
summary(m1)
#m2 = lmer(data=tmp, e_index_norm ~ sa_val_norm + sa_int_norm + follow_norm + (1|org_type) + (1|month))
#m2 = lmer(data=tmp, e_index_norm ~ sa_val_norm + sa_int_norm + follow_norm + (1|month))
#summary(m2)
```

## 230418: growth analysis (cont.)

```{r, purl=T}
#| eval: true
#| output: true
# load functions
source("socm_sa_functions.R")
# aggregate by org
tmp = dvs_org_aggregate(dtp)
# get org_type
tmp = tmp |> group_by(org) |> mutate(id=row_number()) |> 
left_join(dtp |> select(3, 27) |> group_by(org) |> mutate(id=row_number()), by=c("org","id"))
# aggregate by org_type
tmp = tmp |> group_by(org_type, month) |> summarize(e_index_mean=mean(e_index_mean), e_index_rel_mean=mean(e_index_rel_mean), e_index_norm_mean=mean(e_index_norm_mean), e_index_mean_norm=mean(e_index_mean_norm))
# dvs, wide to long
tmp = tmp |> 
pivot_longer(cols=3:6, names_to="dvs", values_to="e_index")
# points with trend line
tmp |> 
  ggplot(aes(x=month, y=e_index, group=org_type, color=as.factor(org_type))) +
  geom_point() + 
  geom_smooth(method=lm, se=FALSE) + 
  facet_wrap(vars(dvs), scales="free") +
  theme_bw() + 
  labs(title="engagement trend by org_type and measure", x="month", y="e_index")
```

### heatmap

```{r, purl=T}
#| eval: true
#| output: true
# heatmap e_index by time and org type
hm1 = tmp |> filter(dvs=="e_index_mean") |> ggplot(aes(x=month, y=as.factor(org_type))) + geom_raster(aes(fill=e_index))
hm2 = tmp |> filter(dvs=="e_index_mean_norm") |> ggplot(aes(x=month, y=as.factor(org_type))) + geom_raster(aes(fill=e_index))
hm3 = tmp |> filter(dvs=="e_index_norm_mean") |> ggplot(aes(x=month, y=as.factor(org_type))) + geom_raster(aes(fill=e_index))
hm4 = tmp |> filter(dvs=="e_index_rel_mean") |> ggplot(aes(x=month, y=as.factor(org_type))) + geom_raster(aes(fill=e_index))
#
hm = gridExtra::grid.arrange(hm1, hm2, hm3, hm4, ncol=2, nrow=2)
#
hm
```

```{r, purl=T}
#| eval: true
#| output: true
# long format, 8 org_type \* 60 months
tmp = dtp %>% as_tibble() %>% select(c(27,22,11)) %>% 
group_by(org_type, month) %>% summarize(e_index_mean=mean(e_index))
#
tmp %>% 
  ggplot(aes(month, e_index_mean, color=as.factor(org_type))) +
  geom_point() + 
  geom_smooth(method=lm, se=FALSE) + 
  theme_bw() + 
  labs(x="month", y="e_index_mean")
```

## 230322: growth analysis

```{r, purl=T}
#| eval: true
#| output: true
#engagement over time
tmp = dtp %>% select(c(1,27,22,11)) %>% head()
#facet plot bivariate
#p = ggplot(tmp, aes(x=org_type, y=value)) +
#  geom_bar(position='dodge', stat='summary', fun='mean') +
#  facet_wrap(vars(measure), scales="free")
#p
```

```{r, purl=T}
#| eval: true
#| output: true
# dv1
tmp1 = dtp %>% select(c(3,22,11)) %>% 
group_by(org, month) %>% summarize(e_index_mean=mean(e_index))
# dv2
tmp2 = dtp %>% mutate(e_index_rel=e_index/follow) %>% select(c(3,22,28)) %>% 
group_by(org, month) %>% summarize(e_index_rel_mean=mean(e_index_rel))
# dv3
tmp3 = left_join(dtp %>% select(c(1,3,22,11)), dtp %>% select(c(1,3,22,11)) %>% 
group_by(org) %>% group_modify(~ vals_normalize(.x$id,.x$e_index)), by=c("org","id")) %>% 
select(c(2,3,5)) %>% rename(e_index_norm=nv) %>% 
group_by(org, month) %>% summarize(e_index_norm_mean=mean(e_index_norm))
# dv4
tmp4 = left_join(tmp1, tmp1 %>% 
group_by(org) %>% group_modify(~ vals_normalize(.x$month,.x$e_index_mean)) %>% 
rename(month=id, e_index_mean_norm=nv), by=c("org","month")) %>% select(-c(3))
# dvs, join multiple
tmp = tmp1 %>% 
left_join(tmp2, by=c("org","month")) %>% 
left_join(tmp3, by=c("org","month")) %>% 
left_join(tmp4, by=c("org","month"))
# dvs, wide to long
tmp = tmp %>% 
pivot_longer(cols=3:6, names_to="dvs", values_to="e_index")
```

### engagement index, dependent variable

1. **e_index_mean**: per post e_index average per month ("raw engagement scores")
2. **e_index_mean_norm**: normalized per organization values of **e_index_mean** (1. above)
3. **e_index_norm_mean**: per post e_index normalized per organization average per month 
4. **e_index_rel_mean**: per post e_index relative to follower count average per month

```{r, purl=T}
#| eval: true
#| output: true
# line plot
lp = ggplot(
data=tmp %>% filter(org %in% c("ClownerutanGranser","lakareutangranser")), 
aes(x=month, y=e_index, group=org, color=org)) +
  geom_line(linewidth=1) +
  facet_wrap(vars(dvs), scales="free") +
  labs(title="engagement by org and measure")
lp
#  facet_wrap(~dvs)
#  facet_grid(. ~ dvs)
```

### long to wide format

```{r, purl=T}
#| eval: true
#| output: true
dtw = dtp %>% select(c(3,22,11)) %>% 
group_by(org, month) %>% summarize(e_index_mean=mean(e_index)) %>% 
pivot_wider(names_from=month, names_glue="month_{month}", values_from=e_index_mean)
# latent growth model, sem approach
library(lavaan)
#dtw %>% names() %>% sort() %>% paste0("1*",.," +", collapse=' ')
#cnt=0;for (i in dtw %>% names() %>% sort()){cat(paste0(cnt,"*",i," + "));cnt=cnt+1;}
model <- '
# intercept
i =~ 
1*month_31 + 1*month_32 + 1*month_33 + 1*month_34 + 1*month_35 + 1*month_36 + 1*month_37 + 1*month_38 + 1*month_39 + 1*month_40 + 1*month_41 + 1*month_42 + 1*month_43 + 1*month_44 + 1*month_45 + 1*month_46 + 1*month_47 + 1*month_48 + 1*month_49 + 1*month_50 + 1*month_51 + 1*month_52 + 1*month_53 + 1*month_54 + 1*month_55 + 1*month_56 + 1*month_57 + 1*month_58 + 1*month_59 + 1*month_60 + 1*month_61 + 1*month_62 + 1*month_63 + 1*month_64 + 1*month_65 + 1*month_66 + 1*month_67 + 1*month_68 + 1*month_69 + 1*month_70 + 1*month_71 + 1*month_72 + 1*month_73 + 1*month_74 + 1*month_75 + 1*month_76 + 1*month_77 + 1*month_78 + 1*month_79 + 1*month_80 + 1*month_81 + 1*month_82 + 1*month_83 + 1*month_84 + 1*month_85 + 1*month_86 + 1*month_87 + 1*month_88 + 1*month_89 + 1*month_90 
# slope
s =~ 
0*month_31 + 1*month_32 + 2*month_33 + 3*month_34 + 4*month_35 + 5*month_36 + 6*month_37 + 7*month_38 + 8*month_39 + 9*month_40 + 10*month_41 + 11*month_42 + 12*month_43 + 13*month_44 + 14*month_45 + 15*month_46 + 16*month_47 + 17*month_48 + 18*month_49 + 19*month_50 + 20*month_51 + 21*month_52 + 22*month_53 + 23*month_54 + 24*month_55 + 25*month_56 + 26*month_57 + 27*month_58 + 28*month_59 + 29*month_60 + 30*month_61 + 31*month_62 + 32*month_63 + 33*month_64 + 34*month_65 + 35*month_66 + 36*month_67 + 37*month_68 + 38*month_69 + 39*month_70 + 40*month_71 + 41*month_72 + 42*month_73 + 43*month_74 + 44*month_75 + 45*month_76 + 46*month_77 + 47*month_78 + 48*month_79 + 49*month_80 + 50*month_81 + 51*month_82 + 52*month_83 + 53*month_84 + 54*month_85 + 55*month_86 + 56*month_87 + 57*month_88 + 58*month_89 + 59*month_90
'
#
#fit1 <- growth(model, data=dtw)
#summary(fit1, standardized=TRUE)
# visualize path diagram
#install.packages('tidySEM', lib="~/lib/r-cran", dependencies=TRUE)
library(tidySEM)
#graph_sem(model=fit1)
#
#library(lavaanPlot)
#lavaanPlot(model=fit1)
#
#library("DiagrammeR")
#library("semPlot")
#semPaths(fit1, intercept = FALSE, whatLabel = "est", residuals = FALSE, exoCov = FALSE)
```

- [link](https://rstudio-pubs-static.s3.amazonaws.com/78926_5aa94ae32fae49f3a384ce885744ef4a.html)

### wide to long format

```{r, purl=T}
#| eval: true
#| output: true
dtl = dtw %>% 
pivot_longer(cols=2:61, names_to="month", values_to="e_index_mean") %>%
mutate(month=str_extract(month, "[0-9]+$")) %>% mutate_at(c("month"), as.numeric)
# line plot
lp = ggplot(
data = dtl %>% filter(org %in% c("ClownerutanGranser","lakareutangranser")), 
aes(x=month, y=e_index_mean, group=org, color=org)) +
  geom_line()
lp
```

```{r, purl=T}
#| eval: true
#| output: true
dtl %>% 
  filter(org %in% c("ClownerutanGranser","lakareutangranser")) %>% # select just two orgs
  ggplot(aes(month, e_index_mean, color = org)) +
  geom_point() + # points for observations of engagement
  geom_smooth(method = lm, se = FALSE) + # linear line
  theme_bw() + # nice theme
  labs(x = "month", y = "e_index_mean") # nice labels
```

## 230315: bivariate org type

```{r, purl=T}
#wide to long format
tmp = dtp %>% select(c(1,27,6,11,14,24)) %>% pivot_longer(cols=3:6, names_to="measure", values_to="value")
#facet plot bivariate
p = ggplot(tmp, aes(x=org_type, y=value)) +
  geom_bar(position='dodge', stat='summary', fun='mean') +
  facet_wrap(vars(measure), scales="free")
p
```

## 230314: resume analysis 

```{r, purl=F}
if (T) {
knitr::knit_exit()
#exit()
#q()
#stop("here..")
}
```

```{r, purl=F}
#| eval: false
#| output: false
if (F) {
# dependencies
install.packages("tidyverse")
install.packages("lme4")
install.packages("plyr")
install.packages("quarto")
}
```

```{r, purl=F}
#| eval: false
#| output: false
#working directory
if (!grepl("/qmd", getwd(), fixed=T)) {setwd("qmd/")}
#clear workspace
rm(list=ls())
#run qmd notebook, dont do this.. 
#quarto::quarto_render("socm_sa.qmd")
#load functions
source("../src/emo-functions.R")
```

```{r, purl=F}
#| eval: false
fn = "https://raw.githubusercontent.com/nils-holmberg/scom-org/main/csv/fb-sa-230314.csv"
fn = "../csv/fb-sa-230314.csv"
dtp = read.table(fn, sep='\t', header=T, strip.white=TRUE, stringsAsFactors=FALSE)
#dtp[9,]
#str(dtp)
#knitr::knit_exit()
```

```{r, purl=F}
#| eval: false
ggplot(dtp, aes(org_type, e_index)) +
  geom_bar(position='dodge', stat='summary', fun='mean')
```

## 230305: resume analysis 

```{r, purl=F}
if (T) {
knitr::knit_exit()
}
```

### replicate project

some explanations of code cell in markdown..

```{r, purl=F}
#| eval: false
if (F) {
# clone github repo
usethis::create_from_github("https://github.com/nils-holmberg/scom-org.git", destdir = "/content/", fork = FALSE)
# go to repo dir
setwd("/content/scom-org/")
list.files()
# delete repo dir, to start over
unlink("/content/scom-org/", recursive=TRUE)
}
```

```{r, purl=F}
#| eval: false
if (F) {
# dependencies
install.packages("tidyverse")
install.packages("lme4")
install.packages("plyr")
}
```

### start here on posit.cloud

link here [posit](https://posit.cloud)

```{r, purl=F}
#| eval: false
if (F) {
# unzip data file
unzip("../csv/fb-sa-210305.csv.zip", exdir="../csv")
}
```

```{r, purl=F}
#| eval: false
#clear workspace
rm(list=ls())
#load functions
source("../src/emo-functions.R")
#
#get records, with emojis (191119)
dfp = posts_get(fn='../csv/fb-sa-210305.csv')
#
```

```{r, purl=F}
#| eval: false
#aggregate measures by organization
colv = c("e_index","sa_val","sa_int","sa_frq","wc","follow")
dfo = orgs_aggregate(dfp, colv)
#column indices
coli = data.frame(test=names(dfo),some=1:length(names(dfo))) %>% filter(!grepl("_se|frq|wc",test)) %>% pull(some)
knitr::kable(dfo %>% as_tibble() %>% select(all_of(coli)) %>% head(), format="pipe", digits=2, caption='aggregate', booktabs=TRUE)
```

### ingest new data

```{r, purl=F}
#| eval: false
#aggregate measures by organization, add org type variable
xls = readxl::read_excel("../tmp/fb-org-type-nw.xlsx", sheet=1)
xls = readxl::read_excel("../tmp/fb-org-type-nw-ng.xlsx", sheet=1)
xls = xls %>% slice(1:125) %>% select("org","Agreed type") #select("org","Typ")
xls = rename(xls, org_type="Agreed type")
dto = left_join(dfo, xls, by=join_by(org))
knitr::kable(dto, format="pipe", digits=2, caption='aggregate, org type', booktabs=TRUE)
```

```{r, purl=F}
#| eval: false
sum(table(dto$org_type))
```

### scale up

```{r, purl=F}
#| eval: false
dtp = left_join(dfp, xls, by=join_by(org)) %>% as_tibble()
table(dtp$org_type)
sum(table(dtp$org_type))
#str(dtp)
write.table(dtp, "../csv/fb-sa-230314.csv", sep="\t", quot=T, row.names=F)
```








