{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment analysis\n",
    "- requires normalized dataset with emoji to text conversion\n",
    "- outputs afinn sentiment values for english and swedish text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import nltk\n",
    "from datetime import datetime\n",
    "import string\n",
    "import sys\n",
    "# afinn sentiment analysis\n",
    "sys.path.append(\"/home/sol-nhl/dev/r-cran/scom-org/get/afinn/\")\n",
    "from afinn import Afinn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use %cpaste and -- in ipython console\n",
    "def small_test(dfn=None):\n",
    "    if not dfn:\n",
    "        # great things have small beginnings\n",
    "        sent = \"an amazing and excellent foo bar, but terrible and confusing.\"\n",
    "        cols = ['id','text']\n",
    "        data = np.array([[1,2,3],[sent,'',sent]]).T\n",
    "        dfs = pd.DataFrame(data, columns=cols)\n",
    "    else:\n",
    "        # or, with some actual data\n",
    "        dfs = dfn[['post_id','post_message']].head(100)\n",
    "        dfs.columns = ['id', 'text']\n",
    "    #\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use %cpaste and -- in ipython console\n",
    "def unnest_tokens(dfs, lang='english'):\n",
    "    print(\"ut: lang \"+lang)\n",
    "    dfs.columns = ['id', 'text']\n",
    "    dfs = dfs.copy()\n",
    "    # stop words\n",
    "    stop = nltk.corpus.stopwords.words(lang) + list(string.punctuation)\n",
    "    # ################## tokenize text\n",
    "    # dfs[\"tokens\"] = dfs[\"text\"].str.lower()\n",
    "    # dfs[\"tokens\"] = dfs.tokens.apply(nltk.word_tokenize)\n",
    "    ts = dfs.text.str.lower().str.split()\n",
    "    dfs[\"tokens\"] = ts\n",
    "    dfs[\"tokens\"] = dfs['tokens'].apply(lambda x: [item for item in x if item not in stop])\n",
    "    # ################## unnest tokens\n",
    "    # set an index (each column will inherit it)\n",
    "    # dfi = df.set_index(['ID', 'Year'])\n",
    "    dfi = dfs[['id','tokens']].set_index(['id'])\n",
    "    # the trick\n",
    "    unnested_lst = []\n",
    "    for col in dfi.columns:\n",
    "        unnested_lst.append(dfi[col].apply(pd.Series).stack())\n",
    "    dft = pd.concat(unnested_lst, axis=1, keys=dfi.columns)\n",
    "    #\n",
    "    return dft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(dft, slex='afinn', lang='en', emot=True):\n",
    "    print(\"sa: lang \"+lang+\", aggregate\")\n",
    "    # ################## sentiment analysis, valence\n",
    "    afinn = Afinn(language=lang, emoticons=emot)\n",
    "    dft['sa_val'] = dft.tokens.apply(afinn.score)\n",
    "    dft['sa_pos'] = dft.sa_val.where(dft.sa_val > 0)\n",
    "    dft['sa_neg'] = dft.sa_val.where(dft.sa_val < 0)\n",
    "    dft.reset_index(inplace=True)\n",
    "    dft['sa_frq'] = np.where(dft['sa_val']!=0, 1.0, np.nan)\n",
    "    print(dft.sa_frq.shape)\n",
    "    # df = pd.DataFrame({'sa_frq': pd.Series(np.where(dft['sa_val']!=0, 1.0, np.nan))})\n",
    "    # dft = pd.concat([dft, df], axis=1)\n",
    "    #\n",
    "    return dft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function aggregate sentiment values over posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_tokens(dft):\n",
    "    # aggregate sa, positive, negative sentiments\n",
    "    # dfa = dft.groupby(['id'])['sa_'].agg({'returns':{'Mean': np.mean, 'Sum': np.sum}})\n",
    "    dfa = dft.groupby(['id'])['sa_val','sa_pos','sa_neg','sa_frq'].sum().reset_index()\n",
    "    #\n",
    "    return dfa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function merge emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_emojis(dfa, dfa_em):\n",
    "    dfe = pd.merge(dfa, dfa_em, how='left', on=['id'])\n",
    "    dfe['sa_val'] = dfe.sa_val_x + dfe.sa_val_y\n",
    "    dfe['sa_pos'] = dfe.sa_pos_x + dfe.sa_pos_y\n",
    "    dfe['sa_neg'] = dfe.sa_neg_x + dfe.sa_neg_y\n",
    "    dfe['sa_frq'] = dfe.sa_frq_x + dfe.sa_frq_y\n",
    "    # check output\n",
    "    dfe.to_csv('tmp/sa-text-emoji.csv', sep='\\t', quoting=csv.QUOTE_NONNUMERIC, header=True, index=None)\n",
    "    # \n",
    "    return dfe[['id','sa_val','sa_pos','sa_neg','sa_frq']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # ################## read, clean dataset\n",
    "    # dfn = pd.read_csv('csv/civil-society-190415.csv', sep='\\t')\n",
    "    # dfn = pd.read_csv('csv/civil-society-191118.csv', sep='\\t')\n",
    "    # new ~100K facebook dataset 210304\n",
    "    dfn = pd.read_csv('../csv/fb-emoji-text.csv', sep='\\t')\n",
    "    dfn.post_message.replace(np.nan, 'string', inplace=True)\n",
    "    # added emoji analysis 191118\n",
    "    dfn.emoji.replace(np.nan, 'string', inplace=True)\n",
    "    dfn.post_lang.replace('se', 'sv', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
